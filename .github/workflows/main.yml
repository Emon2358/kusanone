name: Website Content Scraper with Crocseek Proxy

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target website URL to scrape'
        required: true
      proxy_url:
        description: 'Optional additional proxy URL (format: http://user:pass@host:port)'
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 selenium webdriver-manager lxml pyppeteer aiohttp
      
      - name: Extract site name
        id: site_name
        run: |
          SITE_NAME=$(python3 -c "from urllib.parse import urlparse; import sys; url='${{ github.event.inputs.target_url }}'; parsed=urlparse(url); print(parsed.netloc.replace('www.', ''))")
          echo "SITE_NAME=${SITE_NAME}" >> $GITHUB_ENV
          echo "site_name=${SITE_NAME}" >> $GITHUB_OUTPUT
      
      - name: Run website scraper
        run: |
          mkdir -p "${{ env.SITE_NAME }}"
          python3 scraper.py
        env:
          TARGET_URL: ${{ github.event.inputs.target_url }}
          CROCSEEK_PROXY_BASE: "https://cdn.blockaway.net/_ja/"
          ADDITIONAL_PROXY_URL: ${{ github.event.inputs.proxy_url }}
          SITE_FOLDER: ${{ env.SITE_NAME }}
      
      - name: List scraped files
        run: |
          echo "Scraped content saved to ${{ env.SITE_NAME }}/"
          find "${{ env.SITE_NAME }}" -type f | wc -l
      
      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add "${{ env.SITE_NAME }}/"
          git commit -m "Add scraped content for ${{ env.SITE_NAME }}" || echo "No changes to commit"
          git push
