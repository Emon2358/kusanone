name: Website Content Scraper and GitHub Pages Deployment

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target website URL to scrape'
        required: true
      proxy_url:
        description: 'Optional proxy URL (format: http://user:pass@host:port)'
        required: false

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 selenium webdriver-manager lxml pyppeteer aiohttp
      
      - name: Extract site name
        id: site_name
        run: |
          SITE_NAME=$(python3 -c "from urllib.parse import urlparse; import sys; url='${{ github.event.inputs.target_url }}'; parsed=urlparse(url); print(parsed.netloc.replace('www.', ''))")
          echo "SITE_NAME=${SITE_NAME}" >> $GITHUB_ENV
          echo "site_name=${SITE_NAME}" >> $GITHUB_OUTPUT
      
      - name: Run website scraper
        run: |
          mkdir -p "docs"
          python3 scraper.py
        env:
          TARGET_URL: ${{ github.event.inputs.target_url }}
          PROXY_URL: ${{ github.event.inputs.proxy_url }}
          SITE_FOLDER: "docs"
      
      - name: List scraped files
        run: |
          echo "Scraped content saved to docs/"
          find "docs" -type f | wc -l
      
      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add docs/
          git commit -m "Add scraped content for ${{ env.SITE_NAME }} to GitHub Pages" || echo "No changes to commit"
          git push
      
      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@4.1.4
        with:
          branch: gh-pages
          folder: docs
          clean: true
